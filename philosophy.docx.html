<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c4{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:left;height:11pt}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c12{color:#000000;text-decoration:none;vertical-align:baseline;font-size:17pt;font-family:"Arial";font-style:normal}.c9{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c13{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c11{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c1{color:inherit;text-decoration:inherit}.c8{font-style:italic}.c10{font-size:13pt}.c5{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c11 doc-content"><p class="c2"><span class="c3">We have a very different approach to replications compared to previous initiatives. Here is a brief summary of how we define terms and think about things: </span></p><p class="c0"><span class="c3"></span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c10 c5">We are interested in effects, not papers</span></p><p class="c2"><span class="c3">We are interested in effects, like &ldquo;prozac helps people with depression&rdquo;, &ldquo;LK-99 is a superconductor&rdquo;, or &ldquo;people drink less from red-labeled cups than blue-labeled cups.&rdquo; </span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c4">Our definition of replication </span></p><p class="c2"><span>We define a </span><span class="c5">replication</span><span>&nbsp;as &ldquo;a</span><span>n experiment which is done to test an effect claim made in prior research.&rdquo; (closely following </span><span class="c13"><a class="c1" href="https://www.google.com/url?q=https://journals.plos.org/plosbiology/article?id%3D10.1371/journal.pbio.3000691&amp;sa=D&amp;source=editors&amp;ust=1762112589185089&amp;usg=AOvVaw1cyvUkeng6lC4W8PNUtjYR">Nosek &amp; Errington, 2020</a></span><span>)</span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c4">A replication may use similar methods or very different methods</span></p><p class="c2"><span class="c3">The replication experiment may use methods very similar to the prior experiment, or completely different methods. The important thing is whether the effect being tested for is the same, not the particular methods used to test for the effect. </span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c4">Results of replication experiments are discretized into four categories </span></p><p class="c2"><span class="c3">We classify the replication experiment results into four categories: </span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c5">Successful </span><span class="c3">- the new experiment found statistically significant evidence the effect exists. &nbsp;</span></p><p class="c2"><span class="c5">Inconclusive</span><span class="c3">&nbsp;- the new experiment could not determine one way or another whether the effect exists in a statistically significant manner. </span></p><p class="c2"><span class="c5">Unsuccessful</span><span class="c3">&nbsp;- the new experiment found statistically significant evidence that the effect does not exist. </span></p><p class="c2"><span class="c5">Reversal</span><span class="c3">&nbsp;- the new experiment found statistically significant evidence for the opposite effect. </span></p><p class="c0"><span class="c3"></span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c4">Statistics from replication experiments are saved to analyze the magnitude of effects, when possible</span></p><p class="c2"><span>The classification we just mentioned says nothing about the magnitude of an effect. Our first analysis is not concerned with magnitude. However, we pull down data on effect magnitudes when possible. However, comparing the effect magnitudes measured by different experiments can be tricky. For instance, one study might test whether Prozac helps with depression using a Beck Depression Inventory administered after three weeks, while another study might use a Hamilton Depression Rating Scale administered at three months. Where possible we compare experimental findings using a standard scale or effect size measurement device like Cohen&rsquo;s </span><span class="c8">d</span><span class="c3">.</span></p><p class="c0"><span class="c6"></span></p><p class="c0"><span class="c6"></span></p><p class="c2"><span class="c4">Re-analyses of previously published data are not replications</span></p><p class="c2"><span class="c3">As just mentioned, a replication must involve a new experiment. Therefore we do not consider re-analyses of previously published data to be replications. We note that previous authors have considered the reanalysis of data as &quot;technical replications&rdquo;. Currently our database does not contain technical replications, although it may in the future. </span></p><p class="c0"><span class="c3"></span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c5 c10">The discovery of mistakes in prior work is not a &ldquo;replication failure&rdquo;</span></p><p class="c2"><span>We are interested in the discovery of mistakes, but we consider them &ldquo;errata&rdquo;. In the future we may have a separate database for mistakes, errors, etc. </span></p><p class="c0"><span class="c3"></span></p><p class="c0"><span class="c3"></span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c5 c12">Further Discussion</span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c4">How we define &ldquo;replication&rdquo; vs other definitions</span></p><p class="c2"><span>Our definition of a &ldquo;replication experiment&rdquo; is very broad, and some may think it too broad. Researchers discussing replication generally distinguish two or more forms of replication, such as: <br><br></span><span class="c5">&ldquo;Technical&rdquo; replication (also called or &ldquo;robustness checking&rdquo;) - </span><span class="c3">where a new experiment is not done, but raw data from an existing experiment is reanalyzed using the reported procedures. Or, it may involve simply running provided code on data to get results (this is called &ldquo;frictionless&rdquo; reproduction). &nbsp;</span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c5">&ldquo;Exact&rdquo;, &ldquo;direct&rdquo;, or &ldquo;narrow-sense&rdquo; replication - </span><span class="c3">where an experimental procedure is repeated as closely as possible, usually following the specifications for the procedure given in the original paper. This is the most common understanding of the term &ldquo;replication&rdquo;. </span></p><p class="c2"><span><br></span><span class="c5">&ldquo;Close&rdquo; or &ldquo;systematic&rdquo; replication - </span><span class="c3">where an experimental procedure is repeated closely, but with one or more intentional changes. <br></span></p><p class="c2"><span>&ldquo;</span><span class="c5">Conceptual&rdquo; or &ldquo;broad-sense&rdquo; replication</span><span class="c3">&nbsp;- where a finding from a previous experiment is tested in a new experiment using a different experimental procedure.</span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c3">While all these terms have merit, they are hard to define precisely, with the exception of &ldquo;technical replication&rdquo;, which we don&rsquo;t really view as a replication since no new experiment is done. </span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c3">Clearly, replication is a spectrum, ranging from a &ldquo;direct&rdquo;/&rdquo;exact&rdquo; replication to &nbsp;&ldquo;broad-sense&rdquo; replication. Instead of trying to distinguish different degrees of replication, we consider any experiment on the spectrum to be a replication. This simplifies our work greatly, making it easier for us to achieve scale with our database. </span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c3">At the end of the day, we are most interested in whether scientist&rsquo;s claims hold up when subjected to additional experimental tests. If science is healthy, claims should hold up. If science is unhealthy, claims will not replicate (due to methodological/logical/mathematical errors, other mistakes, improper reporting, intentional fraud, etc). </span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c4">&ldquo;Original experiment&rdquo; vs &ldquo;replication experiment&rdquo;</span></p><p class="c2"><span class="c3">We typically define the &ldquo;original experiment&quot; as the earliest published experiment that resulted in a claim that an effect exists. We define a &ldquo;replication experiment&rdquo; as any experiment published after the original experiment was published which tested for the same effect. </span></p><p class="c0"><span class="c3"></span></p><p class="c0"><span class="c3"></span></p><p class="c2"><span class="c4">We are interested in effects, not papers</span></p><p class="c2"><span class="c6">We believe the proper level of analysis is effects, not papers. While it is often true that scientific papers have one central claim, most papers report many effects. A replication paper may replicate some of those effects and fail to replicate others. </span></p><p class="c0"><span class="c6"></span></p><p class="c2"><span class="c4">We are interested in the general effects that scientists claim</span></p><p class="c2"><span class="c10">Scientific papers often have one or more major claims, like</span><span class="c6">&nbsp;&ldquo;Prozac helps with depression&rdquo;. In a narrow sense all an experiment may have shown was &ldquo;Prozac helps with depression in people diagnosed with depression by a clinician at a Houston-area hospital system in the years 2010-2015&rdquo;, but based on theoretical considerations, the authors claim their work gives strong evidence for the general effect that &ldquo;Prozac helps with depression&rdquo;. We are most interested in the replicability of the general effects that scientists claim, not more narrow readings of an experiment. Other examples of general claims are &ldquo;neutrinos can travel faster than light&rdquo;, &ldquo;the MMR vaccine causes autism&rdquo;, &ldquo;power posing increases success in job interviews&rdquo;, and &ldquo;water can exist in a polymerized form&rdquo; (all of those claims failed replication and are now considered false). </span></p><p class="c0"><span class="c3"></span></p><p class="c0"><span class="c5 c9"></span></p><p class="c7"><span class="c3"></span></p></body></html>